{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# bertchunker: default program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from default import *\n",
    "import os, sys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the default solution on dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_projector.weight', 'vocab_transform.weight', 'vocab_transform.bias', 'vocab_layer_norm.weight', 'vocab_layer_norm.bias', 'vocab_projector.bias']\n",
      "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1027/1027 [00:20<00:00, 51.11it/s]\n"
     ]
    }
   ],
   "source": [
    "chunker = FinetuneTagger(os.path.join('..', 'data', 'chunker'), modelsuffix='.pt')\n",
    "decoder_output = chunker.decode(os.path.join('..', 'data', 'input', 'dev.txt'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ignore the warnings from the transformers library. They are expected to occur."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the default output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "processed 23663 tokens with 11896 phrases; found: 13226 phrases; correct: 9689.\n",
      "accuracy:  87.04%; (non-O)\n",
      "accuracy:  87.45%; precision:  73.26%; recall:  81.45%; FB1:  77.14\n",
      "             ADJP: precision:  13.32%; recall:  53.98%; FB1:  21.37  916\n",
      "             ADVP: precision:  31.16%; recall:  58.79%; FB1:  40.73  751\n",
      "            CONJP: precision:   0.00%; recall:   0.00%; FB1:   0.00  8\n",
      "             INTJ: precision:   0.00%; recall:   0.00%; FB1:   0.00  11\n",
      "              LST: precision:   0.00%; recall:   0.00%; FB1:   0.00  3\n",
      "               NP: precision:  80.58%; recall:  80.86%; FB1:  80.72  6258\n",
      "               PP: precision:  95.97%; recall:  86.93%; FB1:  91.23  2211\n",
      "              PRT: precision:  22.15%; recall:  77.78%; FB1:  34.48  158\n",
      "             SBAR: precision:  36.12%; recall:  80.17%; FB1:  49.80  526\n",
      "              UCP: precision:   0.00%; recall:   0.00%; FB1:   0.00  64\n",
      "               VP: precision:  83.75%; recall:  84.33%; FB1:  84.04  2320\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(73.25722062603963, 81.44754539340954, 77.13557837751772)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flat_output = [ output for sent in decoder_output for output in sent ]\n",
    "sys.path.append('..')\n",
    "import conlleval\n",
    "true_seqs = []\n",
    "with open(os.path.join('..', 'data', 'reference', 'dev.out')) as r:\n",
    "    for sent in conlleval.read_file(r):\n",
    "        true_seqs += sent.split()\n",
    "conlleval.evaluate(true_seqs, flat_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Documentation\n",
    "\n",
    "Write some beautiful documentation of your program here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, the current model is not very good at handling noise in the testing data. What we need to do is introduce mechanisms and strategies to\n",
    "train the model to handle noise so that we can improve our F-score accuracy and create more robust chunking."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis\n",
    "\n",
    "Do some analysis of the results. What ideas did you try? What worked and what did not?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first method we will try is to add adversarial training to simulate noise functions to so that the model is better equipped to handle the testing\n",
    "data. To do this, we will implement 6 noise functions into the chunker.py file to: substitute_character, omit_character, phonetic_mispelling, \n",
    "insert_random_character, keyboard_typo, and and swap_adjacent_characters. We will also implement a probability such that only 12% of words will have\n",
    "noise added to them to start off with the training. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random \n",
    "\n",
    "# Function simulates typographical errors by substituting one character for another\n",
    "def substitute_character(word):\n",
    "    if len(word) > 1:\n",
    "        index = random.randint(0, len(word) - 1)\n",
    "        substitute_with = chr(random.randint(97, 122)) # ASCII range for lower case letters\n",
    "        return word[:index] + substitute_with + word[index + 1:]\n",
    "    return word\n",
    "\n",
    "# Function simulates missing characters, common in fast typing\n",
    "def omit_characters(word):\n",
    "    if len(word) > 1:\n",
    "        index = random.randint(0, len(word) - 1)\n",
    "        return word[:index] + word[index + 1:]\n",
    "    return word\n",
    "\n",
    "# Function simulates phonetic errors\n",
    "\n",
    "phonetic_similarities = {\n",
    "    'c': ['k', 's'], 'k': ['c', 'q'], 's' : ['c', 'z', 'ss'], \n",
    "    'q' : ['k'], 'g' : ['j'], 'j' : ['g', 'ge'], 'kn' : ['n'],\n",
    "    'n': ['kn'], 'gh' : ['f', 'ph'], 'f': ['gh', 'ph', 'ff', 'v'], \n",
    "    'ph' : ['gh', 'f'], 'wh' : ['w'], 'w' : ['wh'], 'v' : ['f'],\n",
    "    'a' : ['e'], 'e' : ['a', 'i'], 'i' : ['e']\n",
    "}\n",
    "\n",
    "def phonetic_misspelling(word):\n",
    "    for i, char in enumerate(word):\n",
    "        if char in phonetic_similarities:\n",
    "            substitutes = phonetic_similarities[char]\n",
    "            substitute_with = random.choice(substitutes)\n",
    "            return word[:i] + substitute_with + word[i + 1:]\n",
    "    return word\n",
    "\n",
    "# Function simulates accidental extra character insertion\n",
    "\n",
    "def insert_random_character(word):\n",
    "    if len(word) > 1:\n",
    "        index = random.randint(0, len(word) - 1)\n",
    "        insert_char = chr(random.randint(97, 122)) # ASCII range for lower case letters\n",
    "        return word[:index] + insert_char + word[index:]\n",
    "    return word\n",
    "\n",
    "# Function simulates accidental keyboard typos\n",
    "\n",
    "keyboard_adjacent = {\n",
    "    'a': ['s', 'w', 'q'], 'b': ['v', 'g', 'h', 'n'], 'c' : ['x', 'd', 'f', 'v'],\n",
    "    'd' : ['s', 'e', 'r', 'f', 'c', 'x'], 'e' : ['w', 's', 'd', 'r'], \n",
    "    'f' : ['d', 'r', 't', 'g', 'v', 'c'], 'g' : ['f', 't', 'y', 'h', 'b', 'v'],\n",
    "    'h' : ['g', 'y', 'u', 'j', 'n', 'b'], 'i' : ['u', 'j', 'k', 'o'],\n",
    "    'j' : ['h', 'u', 'i', 'k', 'm', 'n'], 'k' : ['j', 'i', 'o', 'l', 'm'],\n",
    "    'l' : ['k', 'o', 'p'], 'm' : ['n', 'j', 'k'], 'n' : ['b', 'h', 'j', 'm'], \n",
    "    'o' : ['i', 'k', 'l', 'p'], 'p' : ['o', 'l'], 'q' : ['a', 'w'],\n",
    "    'r' : ['e', 'd', 'f', 't'], 's' : ['a', 'w', 'e', 'd', 'x', 'z'], \n",
    "    't' : ['r', 'f', 'g', 'y'], 'u' : ['y', 'h', 'j', 'i'], 'v' : ['c', 'f', 'g', 'b'],\n",
    "    'w' : ['q', 'a', 's', 'e'], 'x' : ['z', 's', 'd', 'c'], 'y' : ['t', 'g', 'h', 'u'],\n",
    "    'z' : ['a', 's', 'x'] \n",
    "}\n",
    "\n",
    "def keyboard_typo(word):\n",
    "    if len(word) > 1:\n",
    "        i = random.randint(0, len(word) - 1)\n",
    "        if word[i] in keyboard_adjacent:\n",
    "            typo = random.choice(keyboard_adjacent[word[i]])\n",
    "            return word[:i] + typo + word[i + 1:]\n",
    "    return word\n",
    "\n",
    "# Function simulates character swap \n",
    "\n",
    "def swap_adjacent_characters(word):\n",
    "    if len(word) > 1:\n",
    "        # Select position to swap with the next character\n",
    "        swap_pos = random.randint(0, len(word) - 2)  \n",
    "        # Swap characters at swap_pos and swap_pos + 1\n",
    "        word = word[:swap_pos] + word[swap_pos + 1] + word[swap_pos] + word[swap_pos + 2:]\n",
    "    return word"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next thing to do, is to write a function to flag whether the model is in training mode or not so that we know whether to add the simulated noise\n",
    "or not. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_in_training_mode():\n",
    "    path_to_search = os.path.join(\"..\", \"data\", \"chunker.pt\")\n",
    "    return not os.path.exists(path_to_search)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the first training, our output is now: \n",
    "processed 23663 tokens with 11896 phrases; found: 11894 phrases; correct: 10786.\n",
    "accuracy:  94.34%; (non-O)\n",
    "accuracy:  94.67%; precision:  90.68%; recall:  90.67%; FB1:  90.68\n",
    "             ADJP: precision:  74.65%; recall:  71.68%; FB1:  73.14  217\n",
    "             ADVP: precision:  72.80%; recall:  72.61%; FB1:  72.70  397\n",
    "            CONJP: precision:  44.44%; recall:  57.14%; FB1:  50.00  9\n",
    "             INTJ: precision: 100.00%; recall: 100.00%; FB1: 100.00  1\n",
    "               NP: precision:  89.85%; recall:  91.94%; FB1:  90.88  6382\n",
    "               PP: precision:  97.33%; recall:  94.22%; FB1:  95.75  2363\n",
    "              PRT: precision:  76.60%; recall:  80.00%; FB1:  78.26  47\n",
    "             SBAR: precision:  93.23%; recall:  75.53%; FB1:  83.45  192\n",
    "               VP: precision:  91.03%; recall:  90.32%; FB1:  90.68  2286\n",
    "dev.out score: 90.6768\n",
    "\n",
    "The F-score has definitely improved. Now, it is time to further optimize the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step was to use two different optimizers with different learning rates for the pre-trained encoder layers and the classification head layer. For instance, the classification head parameters might be better learned with an SGD optimizer and a learning rate of 0.1. Thus, we changed the function \n",
    "init_model_from_scratch to:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_model_from_scratch(self, basemodel, tagset_size, lr):\n",
    "        self.encoder = AutoModel.from_pretrained(basemodel)\n",
    "        self.encoder_hidden_dim = self.encoder.config.hidden_size\n",
    "        self.classification_head = nn.Linear(self.encoder_hidden_dim, tagset_size)\n",
    "        # TODO initialize self.crf_layer in here as well.\n",
    "        \n",
    "        # TODO modify the optimizers in a way that each model part is optimized with a proper learning rate!\n",
    "        encoder_optimizer = optim.Adam(self.encoder.parameters(), lr = lr)\n",
    "        head_optimizer = optim.SGD(self.classification_head.parameters(), lr = 0.10)\n",
    "\n",
    "        self.optimizers = [encoder_optimizer, head_optimizer]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this, we also had to consider increasing the number of epochs to 10 from 5 to handle the increase in complexity and diversity given simulated noise in training data. \n",
    "\n",
    "Now our output after retraining the model is:\n",
    "processed 23663 tokens with 11896 phrases; found: 11821 phrases; correct: 10796.\n",
    "accuracy:  94.17%; (non-O)\n",
    "accuracy:  94.57%; precision:  91.33%; recall:  90.75%; FB1:  91.04\n",
    "             ADJP: precision:  77.23%; recall:  69.03%; FB1:  72.90  202\n",
    "             ADVP: precision:  79.43%; recall:  69.85%; FB1:  74.33  350\n",
    "            CONJP: precision:  50.00%; recall:  57.14%; FB1:  53.33  8\n",
    "             INTJ: precision: 100.00%; recall: 100.00%; FB1: 100.00  1\n",
    "               NP: precision:  90.97%; recall:  92.06%; FB1:  91.51  6312\n",
    "               PP: precision:  97.33%; recall:  94.06%; FB1:  95.67  2359\n",
    "              PRT: precision:  75.00%; recall:  80.00%; FB1:  77.42  48\n",
    "             SBAR: precision:  92.86%; recall:  76.79%; FB1:  84.06  196\n",
    "               VP: precision:  89.59%; recall:  91.19%; FB1:  90.39  2345\n",
    "dev.out score: 91.0402\n",
    "\n",
    "Its getting even better! The next plan, is to test out the probability of adding noise to a word, and applying different learning rates to see what values will further optimize the model. Given that the probability was 12% for adding noise to a word, lets test out going to the extreme and decreasing the probability to 0.05% to see if perhaps we are adding too much noise to the training data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_conll(handle, input_idx=0, label_idx=2):\n",
    "    conll_data = []\n",
    "    contents = re.sub(r'\\n\\s*\\n', r'\\n\\n', handle.read())\n",
    "    contents = contents.rstrip()\n",
    "    for sent_string in contents.split('\\n\\n'):\n",
    "        annotations = list(zip(*[ word_string.split() for word_string in sent_string.split('\\n') ]))\n",
    "        assert(input_idx < len(annotations))\n",
    "\n",
    "        if label_idx < 0:\n",
    "            conll_data.append( annotations[input_idx] )\n",
    "            logging.info(\"CoNLL: {}\".format( \" \".join(annotations[input_idx])))\n",
    "        else:\n",
    "            assert(label_idx < len(annotations))\n",
    "\n",
    "            noise_probability = 0.0005 # This will be adjusted as needed\n",
    "            noisy_annotations = []\n",
    "\n",
    "            if model_in_training_mode():\n",
    "                for word in annotations[input_idx]:\n",
    "                    if random.random() < noise_probability:\n",
    "                        # Randomly choose a noise function and apply it to the word\n",
    "                        word = random.choice([substitute_character, omit_characters, phonetic_misspelling, \n",
    "                                          insert_random_character, keyboard_typo, swap_adjacent_characters])(word)\n",
    "            \n",
    "                    noisy_annotations.append(word)\n",
    "                annotations = list(annotations) # Convert tuple to list to modify contents\n",
    "                annotations[input_idx] = tuple(noisy_annotations) # Replace words with noisy words\n",
    "\n",
    "            conll_data.append((annotations[input_idx], annotations[label_idx] ))\n",
    "            logging.info(\"CoNLL: {} ||| {}\".format( \" \".join(annotations[input_idx]), \" \".join(annotations[label_idx])))\n",
    "    return conll_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our output is now:\n",
    "processed 23663 tokens with 11896 phrases; found: 11719 phrases; correct: 10432.\n",
    "accuracy:  92.49%; (non-O)\n",
    "accuracy:  93.06%; precision:  89.02%; recall:  87.69%; FB1:  88.35\n",
    "             ADJP: precision:  74.47%; recall:  61.95%; FB1:  67.63  188\n",
    "             ADVP: precision:  78.64%; recall:  66.58%; FB1:  72.11  337\n",
    "            CONJP: precision:  75.00%; recall:  85.71%; FB1:  80.00  8\n",
    "             INTJ: precision: 100.00%; recall: 100.00%; FB1: 100.00  1\n",
    "               NP: precision:  88.09%; recall:  89.16%; FB1:  88.62  6313\n",
    "               PP: precision:  96.91%; recall:  89.96%; FB1:  93.31  2266\n",
    "              PRT: precision:  72.92%; recall:  77.78%; FB1:  75.27  48\n",
    "             SBAR: precision:  91.40%; recall:  71.73%; FB1:  80.38  186\n",
    "               VP: precision:  86.76%; recall:  89.32%; FB1:  88.02  2372\n",
    "dev.out score: 88.3506\n",
    "\n",
    "It seems we have decreased the probabiity too much. Lets try and amp it up to perhaps 4%?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_conll(handle, input_idx=0, label_idx=2):\n",
    "    conll_data = []\n",
    "    contents = re.sub(r'\\n\\s*\\n', r'\\n\\n', handle.read())\n",
    "    contents = contents.rstrip()\n",
    "    for sent_string in contents.split('\\n\\n'):\n",
    "        annotations = list(zip(*[ word_string.split() for word_string in sent_string.split('\\n') ]))\n",
    "        assert(input_idx < len(annotations))\n",
    "\n",
    "        if label_idx < 0:\n",
    "            conll_data.append( annotations[input_idx] )\n",
    "            logging.info(\"CoNLL: {}\".format( \" \".join(annotations[input_idx])))\n",
    "        else:\n",
    "            assert(label_idx < len(annotations))\n",
    "\n",
    "            noise_probability = 0.04 # This will be adjusted as needed\n",
    "            noisy_annotations = []\n",
    "\n",
    "            if model_in_training_mode():\n",
    "                for word in annotations[input_idx]:\n",
    "                    if random.random() < noise_probability:\n",
    "                        # Randomly choose a noise function and apply it to the word\n",
    "                        word = random.choice([substitute_character, omit_characters, phonetic_misspelling, \n",
    "                                          insert_random_character, keyboard_typo, swap_adjacent_characters])(word)\n",
    "            \n",
    "                    noisy_annotations.append(word)\n",
    "                annotations = list(annotations) # Convert tuple to list to modify contents\n",
    "                annotations[input_idx] = tuple(noisy_annotations) # Replace words with noisy words\n",
    "\n",
    "            conll_data.append((annotations[input_idx], annotations[label_idx] ))\n",
    "            logging.info(\"CoNLL: {} ||| {}\".format( \" \".join(annotations[input_idx]), \" \".join(annotations[label_idx])))\n",
    "    return conll_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our output is now: \n",
    "processed 23663 tokens with 11896 phrases; found: 12053 phrases; correct: 11081.\n",
    "accuracy:  95.43%; (non-O)\n",
    "accuracy:  95.67%; precision:  91.94%; recall:  93.15%; FB1:  92.54\n",
    "             ADJP: precision:  71.74%; recall:  73.01%; FB1:  72.37  230\n",
    "             ADVP: precision:  70.74%; recall:  77.14%; FB1:  73.80  434\n",
    "            CONJP: precision:  71.43%; recall:  71.43%; FB1:  71.43  7\n",
    "             INTJ: precision: 100.00%; recall: 100.00%; FB1: 100.00  1\n",
    "               NP: precision:  92.01%; recall:  94.02%; FB1:  93.01  6373\n",
    "               PP: precision:  96.31%; recall:  97.26%; FB1:  96.78  2465\n",
    "              PRT: precision:  84.21%; recall:  71.11%; FB1:  77.11  38\n",
    "             SBAR: precision:  91.12%; recall:  82.28%; FB1:  86.47  214\n",
    "               VP: precision:  93.32%; recall:  92.80%; FB1:  93.06  2291\n",
    "dev.out score: 92.5383\n",
    "\n",
    "That is awesome! It seems like we got a huge boost in the accuracy. Lets try to alter it again and see what the output is. We will alter the probability to 3% now. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_conll(handle, input_idx=0, label_idx=2):\n",
    "    conll_data = []\n",
    "    contents = re.sub(r'\\n\\s*\\n', r'\\n\\n', handle.read())\n",
    "    contents = contents.rstrip()\n",
    "    for sent_string in contents.split('\\n\\n'):\n",
    "        annotations = list(zip(*[ word_string.split() for word_string in sent_string.split('\\n') ]))\n",
    "        assert(input_idx < len(annotations))\n",
    "\n",
    "        if label_idx < 0:\n",
    "            conll_data.append( annotations[input_idx] )\n",
    "            logging.info(\"CoNLL: {}\".format( \" \".join(annotations[input_idx])))\n",
    "        else:\n",
    "            assert(label_idx < len(annotations))\n",
    "\n",
    "            noise_probability = 0.03 # This will be adjusted as needed\n",
    "            noisy_annotations = []\n",
    "\n",
    "            if model_in_training_mode():\n",
    "                for word in annotations[input_idx]:\n",
    "                    if random.random() < noise_probability:\n",
    "                        # Randomly choose a noise function and apply it to the word\n",
    "                        word = random.choice([substitute_character, omit_characters, phonetic_misspelling, \n",
    "                                          insert_random_character, keyboard_typo, swap_adjacent_characters])(word)\n",
    "            \n",
    "                    noisy_annotations.append(word)\n",
    "                annotations = list(annotations) # Convert tuple to list to modify contents\n",
    "                annotations[input_idx] = tuple(noisy_annotations) # Replace words with noisy words\n",
    "\n",
    "            conll_data.append((annotations[input_idx], annotations[label_idx] ))\n",
    "            logging.info(\"CoNLL: {} ||| {}\".format( \" \".join(annotations[input_idx]), \" \".join(annotations[label_idx])))\n",
    "    return conll_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our output is now: \n",
    "processed 23663 tokens with 11896 phrases; found: 11995 phrases; correct: 11091.\n",
    "accuracy:  95.60%; (non-O)\n",
    "accuracy:  95.80%; precision:  92.46%; recall:  93.23%; FB1:  92.85\n",
    "             ADJP: precision:  70.98%; recall:  80.09%; FB1:  75.26  255\n",
    "             ADVP: precision:  79.73%; recall:  74.12%; FB1:  76.82  370\n",
    "            CONJP: precision:  55.56%; recall:  71.43%; FB1:  62.50  9\n",
    "             INTJ: precision:   0.00%; recall:   0.00%; FB1:   0.00  0\n",
    "               NP: precision:  92.96%; recall:  94.18%; FB1:  93.56  6319\n",
    "               PP: precision:  95.57%; recall:  97.21%; FB1:  96.39  2483\n",
    "              PRT: precision:  74.47%; recall:  77.78%; FB1:  76.09  47\n",
    "             SBAR: precision:  90.55%; recall:  76.79%; FB1:  83.11  201\n",
    "               VP: precision:  92.86%; recall:  93.14%; FB1:  93.00  2311\n",
    "dev.out score: 92.8467\n",
    "\n",
    "We can see the F-score accuracy increased again, this indicates that our optimal probability is between 0.05% and 3%. The next part is to see, what learning rates will be optimal for the classification head. Lets begin with dropping the learning rate from 0.1 to 0.01, as it is possible that the learning rate is too high which would result in the loss function value increasing or sharply stop decreasing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_model_from_scratch(self, basemodel, tagset_size, lr):\n",
    "        self.encoder = AutoModel.from_pretrained(basemodel)\n",
    "        self.encoder_hidden_dim = self.encoder.config.hidden_size\n",
    "        self.classification_head = nn.Linear(self.encoder_hidden_dim, tagset_size)\n",
    "        # TODO initialize self.crf_layer in here as well.\n",
    "        \n",
    "        # TODO modify the optimizers in a way that each model part is optimized with a proper learning rate!\n",
    "        encoder_optimizer = optim.Adam(self.encoder.parameters(), lr = lr)\n",
    "        head_optimizer = optim.SGD(self.classification_head.parameters(), lr = 0.01)\n",
    "\n",
    "        self.optimizers = [encoder_optimizer, head_optimizer]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "The following is our output:\n",
    "\n",
    "processed 23663 tokens with 11896 phrases; found: 11981 phrases; correct: 11136.\n",
    "accuracy:  95.74%; (non-O)\n",
    "accuracy:  95.83%; precision:  92.95%; recall:  93.61%; FB1:  93.28\n",
    "             ADJP: precision:  75.43%; recall:  77.43%; FB1:  76.42  232\n",
    "             ADVP: precision:  77.41%; recall:  76.63%; FB1:  77.02  394\n",
    "            CONJP: precision:  62.50%; recall:  71.43%; FB1:  66.67  8\n",
    "             INTJ: precision: 100.00%; recall: 100.00%; FB1: 100.00  1\n",
    "               NP: precision:  93.71%; recall:  94.18%; FB1:  93.95  6268\n",
    "               PP: precision:  95.59%; recall:  97.75%; FB1:  96.66  2496\n",
    "              PRT: precision:  72.92%; recall:  77.78%; FB1:  75.27  48\n",
    "             SBAR: precision:  88.39%; recall:  83.54%; FB1:  85.90  224\n",
    "               VP: precision:  93.38%; recall:  93.62%; FB1:  93.50  2310\n",
    "dev.out score: 93.2781\n",
    "\n",
    "From what we can see, the F-score accuracy has significantly increased now which indicates that we either found the right learning rate or chose a low enough learning rate to decrease the loss function value over the epochs. \n",
    "\n",
    "Now, we will to alter the learning rate to 0.02, to test if 0.01 is a low learning rate or just right. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_model_from_scratch(self, basemodel, tagset_size, lr):\n",
    "        self.encoder = AutoModel.from_pretrained(basemodel)\n",
    "        self.encoder_hidden_dim = self.encoder.config.hidden_size\n",
    "        self.classification_head = nn.Linear(self.encoder_hidden_dim, tagset_size)\n",
    "        # TODO initialize self.crf_layer in here as well.\n",
    "        \n",
    "        # TODO modify the optimizers in a way that each model part is optimized with a proper learning rate!\n",
    "        encoder_optimizer = optim.Adam(self.encoder.parameters(), lr = lr)\n",
    "        head_optimizer = optim.SGD(self.classification_head.parameters(), lr = 0.02)\n",
    "\n",
    "        self.optimizers = [encoder_optimizer, head_optimizer]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Our output is now:\n",
    "\n",
    "processed 23663 tokens with 11896 phrases; found: 11969 phrases; correct: 11100.\n",
    "accuracy:  95.66%; (non-O)\n",
    "accuracy:  95.77%; precision:  92.74%; recall:  93.31%; FB1:  93.02\n",
    "             ADJP: precision:  75.56%; recall:  75.22%; FB1:  75.39  225\n",
    "             ADVP: precision:  75.87%; recall:  76.63%; FB1:  76.25  402\n",
    "            CONJP: precision:  71.43%; recall:  71.43%; FB1:  71.43  7\n",
    "             INTJ: precision:   0.00%; recall:   0.00%; FB1:   0.00  0\n",
    "               NP: precision:  93.72%; recall:  94.34%; FB1:  94.03  6278\n",
    "               PP: precision:  94.78%; recall:  97.42%; FB1:  96.08  2509\n",
    "              PRT: precision:  71.43%; recall:  66.67%; FB1:  68.97  42\n",
    "             SBAR: precision:  89.32%; recall:  77.64%; FB1:  83.07  206\n",
    "               VP: precision:  93.22%; recall:  93.06%; FB1:  93.14  2300\n",
    "dev.out score: 93.0233\n",
    "\n",
    "We can observe that the F-score decreases slightly now which may indicate that 0.02 is too high of a learning rate. Now, lets try and decrease the learning rate to 0.009 to test if 0.01 is itself also a high learning rate. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_model_from_scratch(self, basemodel, tagset_size, lr):\n",
    "        self.encoder = AutoModel.from_pretrained(basemodel)\n",
    "        self.encoder_hidden_dim = self.encoder.config.hidden_size\n",
    "        self.classification_head = nn.Linear(self.encoder_hidden_dim, tagset_size)\n",
    "        # TODO initialize self.crf_layer in here as well.\n",
    "        \n",
    "        # TODO modify the optimizers in a way that each model part is optimized with a proper learning rate!\n",
    "        encoder_optimizer = optim.Adam(self.encoder.parameters(), lr = lr)\n",
    "        head_optimizer = optim.SGD(self.classification_head.parameters(), lr = 0.009)\n",
    "\n",
    "        self.optimizers = [encoder_optimizer, head_optimizer]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our output is now:\n",
    "\n",
    "processed 23663 tokens with 11896 phrases; found: 12037 phrases; correct: 11144.\n",
    "accuracy:  95.67%; (non-O)\n",
    "accuracy:  95.78%; precision:  92.58%; recall:  93.68%; FB1:  93.13\n",
    "             ADJP: precision:  79.04%; recall:  80.09%; FB1:  79.56  229\n",
    "             ADVP: precision:  73.61%; recall:  76.38%; FB1:  74.97  413\n",
    "            CONJP: precision:  71.43%; recall:  71.43%; FB1:  71.43  7\n",
    "             INTJ: precision: 100.00%; recall: 100.00%; FB1: 100.00  1\n",
    "               NP: precision:  93.59%; recall:  93.92%; FB1:  93.76  6259\n",
    "               PP: precision:  95.32%; recall:  97.58%; FB1:  96.44  2499\n",
    "              PRT: precision:  72.92%; recall:  77.78%; FB1:  75.27  48\n",
    "             SBAR: precision:  89.78%; recall:  85.23%; FB1:  87.45  225\n",
    "               VP: precision:  92.36%; recall:  94.44%; FB1:  93.39  2356\n",
    "dev.out score: 93.1266\n",
    "\n",
    "We can see that 0.009 is a better learning rate than 0.02, although it is also not as good of a learning rate as 0.01. This further implies that 0.01 may be the right learning rate for this classification head and for the model. \n",
    "\n",
    "Therefore, the optimized values for learning rate of classification head is 0.01, and the optimized probability for simulating noise in the data is 3% given the trial and error process of testing different outputs. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
